<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">

	<title> Stackful Coroutine Async Story in Rust </title>

	<meta name="description" content="Another rust async story">
	<meta name="author" content="Xudong-Huang">

	<meta name="apple-mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<link rel="stylesheet" href="reveal.js/css/reveal.css">
	<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">

	<!-- Theme used for syntax highlighting of code -->
	<link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);
	</script>

	<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
</head>

<body>

	<div class="reveal">

		<!-- Any section element inside of this container is displayed as a slide -->
		<div class="slides">
			<section>
				<h1>Stackful Coroutine in Rust</h1>
				<h3>Another async story</h3>
				<p>
					<small>Created by <a href="https://github.com/Xudong-Huang">Xudong-Huang</a> </small>
				</p>
			</section>

			<section data-markdown>
				<script type="text/template">
					## Agenda
					* Stackful Generator
					* Stackful Coroutine
					* Async Io
					* Sync Primitives
					* Timer Management
				</script>
			</section>

			<section data-markdown>
				<script type="text/template">
					## Agenda - continued
					* Coroutine Cancellation
					* Deal with contentions
					* join! and select!
					* Difference with Futures
				</script>
			</section>

			<section>
				<section data-markdown>
					<script type="text/template">
						## Stackful Generator
						
						* generator is a special function with multiple return values
						* `send`/`yield` would switch stack context 
							```rust
							let mut g = Gn::new_scoped(|mut s| {
								s.yield_(17); //--> `yield` switch stack to caller
								              //--> `send` switch stack back from caller
								return 42;    //--> `return` finish the generator
								              //    and switch stack back to caller
							});
							g.for_each(|v| println!("{}", v); // print 17 and 42
							```
						Notes:
						compared with stack frame in normal function calls
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Context management
						* thread local context stack and chain generators
						<div style="text-align: center;"><img src="images/context_stack_gen.png" style="background:none; border:none; box-shadow:none;"></div>
						Note: the root contains no stack but only registers
					</script>
				</section>

				<section data-markdown>
					<script type="text/template">
						## stackful generator key features
						* detect current context type
						* `send` and `yield` with parameters
						* yield internal stack refs
						* always yield to caller
					</script>
				</section>
			</section>

			<section>
				<section data-markdown>
					<script type="text/template">
						## Stackful Coroutine
						* coroutine is a special thread (user space / light)
						* scheduler running on multi-thread
						* semantic blocking is not real blocking
						* call API without directly yield
						* keep the same interface as std library
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Difference with generator
						* coroutine is a special generator
						* stackful coroutine can yield from any point directly to scheduler
						* always yield a "kernel request"
						* when resume the scheduler send back the result
						* init with Coroutine Local Storage

					</script>
				</section>

				<section data-markdown>
					<script type="text/template">
						## user and kernel model
						<div style="text-align: center;"><img src="images/coroutine_stack.png" style="background:none; border:none; box-shadow:none;"></div>
					</script>
				</section>

				<section data-markdown>
					<script type="text/template">
						## the kernel request
						* coroutine signature
						```rust
						type CoroutineImpl = Generator<'static, EventResult, EventSubscriber>;
						```
						* the kernel request
						```rust
						// APIs running after yield to scheduler
						pub trait EventSource {
							/// kernel handler of the event, got the coroutine instance back
							fn subscribe(&mut self, _c: CoroutineImpl);
							/// after yield back process
							fn yield_back(&self, cancel: &'static Cancel) {}
						}
						```
						* construct the kernel request on stack and yield out
					</script>
				</section>

				<section data-markdown>
					<script type="text/template">
						## kernel request example
						```rust
						struct Sleep { dur: Duration }
						
						impl EventSource for Sleep {
							fn subscribe(&mut self, co: CoroutineImpl) {
								// put the coroutine into the timer list
								let sleep_co = Arc::new(AtomicOption::some(co));
								get_scheduler().add_timer(self.dur, sleep_co.clone());
							}
						}

						pub fn sleep(dur: Duration) {
							let sleeper = Sleep { dur };
							yield_with(&sleeper);
						}
						```
					</script>
				</section>

				<section data-markdown>
					<script type="text/template">
						## uniform coroutine and generator
						```rust
						go!(|| {
							let g = Gn::new_scoped(|mut s| {
								for i in 0..1000 {
									// call coroutine API in generator, yield to scheduler
									coroutine::sleep(Duration::from_secs(1));
									// yield to caller
									s.yield_(i);
								}
								1000
							});
					
							g.for_each(|v| { dbg!(v); });
						})
						.wait()
						```
					</script>
				</section>
			</section>

			<section>
				<section data-markdown>
					<script type="text/template">
						## IO sub system
						* yield io kernel request
						* every io kernel request has a timeout property
						* running io related things only on io thread
						* support TCP/UDP/Unix Socket/Windows Pipe
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## the eventloop
						* uniform io event loop (epoll/kqueue/IOCP)
						* event mode: do the real io operation in user space after resume back
						* completion mode: check the io result after resume back
						* dispatch the io request on multiple io thread based on fd
						* io timeout is managed in the eventloop thread
						Note: stackful coroutine not using mio
					</script>
				</section>
			</section>

			<section>
				<section data-markdown>
					<script type="text/template">
						## sync primitive sub system
						* yield blocker kernel request
						* save the suspending coroutines within primitive internal queue
						* scheduling the coroutines on normal scheduler with work stealing
						* support Semphore/Mutex/RwLock/CondVar/SyncFlag/MPSC channel
						Note: SyncFlag is something like Once
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## the blocker
						* all sync primitives are implemented based on blocker
						* the blocker could return Timeout/Canceled/Ok
						* the blocker support running in thread context

						```rust
						pub enum Parker { Coroutine(Park), Thread(ThreadPark) }
						pub enum ParkError { Canceled, Timeout }
						pub struct Blocker { parker: Parker }
						
						impl Blocker {
							pub fn park(&self, timeout: Option<Duration>) -> Result<(), ParkError> {...}
							pub fn unpark(&self) {...}
						}
						```
						Note: the primitives can be cancelled
					</script>
				</section>
			</section>

			<section>
				<section data-markdown>
					<script type="text/template">
						## timer management
						* running timer manager in a separate thread
						* the timer request push to MPSC "priority queue"
						* blocker/sleep would push timeout request to the priority queue
						* when a timeout happened, throw the coroutine into global ready list
					</script>
				</section>
			</section>

			<section>
				<section data-markdown>
					<script type="text/template">
						## coroutine cancellation
						* we trigger a special panic while detect cancel
						* the cancel panic would be caught and we have chance to mark the coroutine as cancelled
						* can only detect cancel when switch from/to kernel
						* the cancel panic would trigger stack unwind and may has bad side effect
						```rust
						let j = go!(move || {
							coroutine::sleep(Duration::from_secs(1000000);
						});
						unsafe { j.coroutine().cancel() };
						assert!(j.joint().is_err()); // Err(Cancel)
						```
					</script>
				</section>
			</section>

			<section>
				<section data-markdown>
					<script type="text/template">
						## Deal with contentions
						* user space and kernel space contention
							- sub system may run the coroutine while it's still in kernel processing
						* sub system contentions
							- io and cancel
							- blocker timeout
							- blocker cancel
						* sync primitive contentions
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## the solutions
						* user space and kernel space contention
							- Delay drop kernel request until the kernel `subscribe()` done
						* use lockless data structures
							- AtomicOption - only one sub system can grab the coroutine
							- atomic queues - Mutex/Semphore queue
						* atomic event exchange algorithm
							- make sure event processed once and only once between event consumer and producer
					</script>
				</section>
			</section>

			<section>
				<section data-markdown>
					<script type="text/template">
						## uniform thread and coroutine
						* we can detect the context when calling blocking API
							 - if current context is thread root
							 - if current context has coroutine local storage
						* when we are calling blocking API in thread context it has the same effect as calling corresponding std API
					</script>
				</section>
			</section>

			<section>
				<section data-markdown>
					<script type="text/template">
						## combine blocking logic
						* `join!()` macro wait all things done
						```rust
						// ref scoped coroutines
						join!(
							rx1.recv().unwrap(),
							mutex1.lock().unwrap(),
						);
						```
						* `select!()` macro wait any thing done first and cancel others
						```rust
						// ref cqueue APIs
						let n = select!(
							x = rx1.recv().unwrap() => println!("got x={} first", x),
							y = rx2.recv().unwrap() => println!("got y={} first", y),
							_ = sleep(Duration::from_secs(1)) => println!("timeout!"),
						);
						```
					</script>
				</section>
			</section>

			<section>
				<section data-markdown>
					<script type="text/template">
						## difference with futures
						* The Good
						    - initiative to learn and use
							- no need to mark with `async` and `await`
							- the APIs could be run within thread context
							- the APIs are compatible with std and stable
						* The Bad
						    - consume more memory
							- context switching is not free
							- more easily stack overflow
						Note: you should tune the stack usage of the application
						      there are tools to show the stack usage
						```
					</script>
				</section>
			</section>

			<section
				data-background-iframe="https://www.techempower.com/benchmarks/#section=data-r17&hw=cl&test=plaintext">
				<div
					style="position: absolute; width: 40%; right: 0; box-shadow: 0 1px 4px rgba(0,0,0,0.5), 0 5px 25px rgba(0,0,0,0.2); background-color: rgba(0, 0, 0, 0.9); color: #fff; padding: 20px; font-size: 20px; text-align: left;">
					<p> CONCLUSION </p>
					<p> - uniform generator and coroutine </p>
					<p> - uniform thread and coroutine </p>
					<p> - uniform linux/bsd/windows </p>
					<p> - compatible API with std library </p>
					<p> - intuitive usage and high performance </p>
				</div>
			</section>

			<section style="text-align: center;">
				<h1>Thanks</h1>
				<p style="text-align: left;">
					- <a href="https://https://github.com/Xudong-Huang/generator-rs">generator-rs</a> <br>
					- <a href="https://github.com/Xudong-Huang/May">May</a>
				</p>
			</section>

		</div>

	</div>

	<script src="reveal.js/lib/js/head.min.js"></script>
	<script src="reveal.js/js/reveal.js"></script>

	<script>

		// More info https://github.com/hakimel/reveal.js#configuration
		Reveal.initialize({
			controls: true,
			progress: true,
			history: true,
			center: true,

			transition: 'slide', // none/fade/slide/convex/concave/zoom

			// More info https://github.com/hakimel/reveal.js#dependencies
			dependencies: [
				{ src: 'reveal.js/lib/js/classList.js', condition: function () { return !document.body.classList; } },
				{ src: 'reveal.js/plugin/markdown/marked.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
				{ src: 'reveal.js/plugin/markdown/markdown.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
				{ src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function () { hljs.initHighlightingOnLoad(); } },
				{ src: 'reveal.js/plugin/search/search.js', async: true },
				{ src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
				{ src: 'reveal.js/plugin/notes/notes.js', async: true }
			]
		});

	</script>

</body>

</html>